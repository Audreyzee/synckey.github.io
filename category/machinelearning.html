<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>A Pelican Blog - machinelearning</title>
        <link rel="stylesheet" href="http://synckey.name/theme/css/main.css" />
        <link href="http://synckey.name/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="A Pelican Blog Atom Feed" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="http://synckey.name/">A Pelican Blog </a></h1>
                <nav><ul>
                    <li><a href="http://synckey.name/category/digest.html">digest</a></li>
                    <li><a href="http://synckey.name/category/ielts.html">ielts</a></li>
                    <li><a href="http://synckey.name/category/life.html">life</a></li>
                    <li class="active"><a href="http://synckey.name/category/machinelearning.html">machinelearning</a></li>
                    <li><a href="http://synckey.name/category/posts.html">posts</a></li>
                    <li><a href="http://synckey.name/category/sfv.html">sfv</a></li>
                    <li><a href="http://synckey.name/category/summery.html">summery</a></li>
                    <li><a href="http://synckey.name/category/tools.html">tools</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="http://synckey.name/read-mat-files-in-python.html">Read .mat Files in Python</a></h1>
<footer class="post-info">
        <abbr class="published" title="2017-03-30T00:00:00+08:00">
                Published: Thu 30 March 2017
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="http://synckey.name/author/andy.html">Andy</a>
        </address>
<p>In <a href="http://synckey.name/category/machinelearning.html">machinelearning</a>.</p>
<p>tags: <a href="http://synckey.name/tag/machine-learning.html">machine learning</a> <a href="http://synckey.name/tag/deep-learning.html">deep learning</a> <a href="http://synckey.name/tag/probability.html">probability</a> </p>
</footer><!-- /.post-info --><p>Some of the open datasets come with matlab format, we can load the matlab format files with python with the following codes :</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.io</span>
<span class="n">mat</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="s1">&#39;file.mat&#39;</span><span class="p">)</span>
</pre></div>


<p>Enjoy^_^</p>
<h4>Reference</h4>
<p><a href="http://stackoverflow.com/questions/874461/read-mat-files-in-python">read-mat-files-in-python</a></p>                </article>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                    <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                    <h1><a href="http://synckey.name/review-of-probability.html" rel="bookmark"
                           title="Permalink to 《概率论》复习笔记">《概率论》复习笔记</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2017-02-20T00:00:00+08:00">
                Published: Mon 20 February 2017
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="http://synckey.name/author/andy.html">Andy</a>
        </address>
<p>In <a href="http://synckey.name/category/machinelearning.html">machinelearning</a>.</p>
<p>tags: <a href="http://synckey.name/tag/machine-learning.html">machine learning</a> <a href="http://synckey.name/tag/deep-learning.html">deep learning</a> <a href="http://synckey.name/tag/probability.html">probability</a> </p>
</footer><!-- /.post-info -->                <h4>1. 随机事件和概率</h4>
<h5>1.1全概率公式</h5>
<p>设事件 $A_1,A_2,\cdots,A_n$ 两两互不相容，$P(A_i)&gt;0(i=1,2,\cdots,n)$，且$\sum\limits_{i=1}^{n}{A_i}=\Omega$，
则对任一事件$B$，有
$$
P(B)=\sum_{i=1}^{n}{P(A_i)\cdot P{(B|A_i)}}.
$$
满足公式中的$A_1,A_2,\cdots,A_n$  叫<strong>完备事件组</strong>。</p>
<h5>1.2贝叶斯公式 …</h5>
                <a class="readmore" href="http://synckey.name/review-of-probability.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="http://synckey.name/summary-concepts-of-deep-learning.html" rel="bookmark"
                           title="Permalink to Summary Concepts of Deep Learning">Summary Concepts of Deep Learning</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2016-03-01T00:00:00+08:00">
                Published: Tue 01 March 2016
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="http://synckey.name/author/andy.html">Andy</a>
        </address>
<p>In <a href="http://synckey.name/category/machinelearning.html">machinelearning</a>.</p>
<p>tags: <a href="http://synckey.name/tag/machine-learning.html">machine learning</a> <a href="http://synckey.name/tag/deep-learning.html">deep learning</a> </p>
</footer><!-- /.post-info -->                <h2>机器学习</h2>
<p>input-&gt;feature representation-&gt;learning algorithm</p>
<h3>监督学习</h3>
<p>标注过的训练数据.</p>
<ul>
<li>标注成本高</li>
<li>数据稀疏</li>
</ul>
<h3>非监督学习</h3>
<p>未标注的数据,让算法自己决定学到什么.</p>
<ul>
<li>数据量大</li>
</ul>
<h3>features</h3>
<p><code>特征的表示对机器学习性能有巨大的影响.</code></p>
<ul>
<li>人工特征筛选,处理,需要非常精细的调整和专业知识.</li>
<li>在很多任务中,很难知道哪些特征需要被抽取出来.例如,想要识别图像中的汽车,我们知道骑车都有轮子,所以我们可能会将轮子当做一个特征,但是实际上很难精确的描述什么是轮子.</li>
</ul>
<h2>神经网络</h2>
<h3>Neurons</h3>
<p><div class="figure">
<img src="/static/images/SingleNeuron.png" alt="SingleNeuron"  width="40%" />
</div></p>
<p>神经网络的基本组成单元,叫神经元(neuron),途中的神经元是一个以$x_1,x_x,x_3$(和一个$+1$截距项(intercept term))为输入,以$h_{W,b}(x)=f(W^Tx)=f …</p>
                <a class="readmore" href="http://synckey.name/summary-concepts-of-deep-learning.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="http://synckey.name/plot-sigmoid-in-matlab.html" rel="bookmark"
                           title="Permalink to Plot Sigmoid in Matlab">Plot Sigmoid in Matlab</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2015-12-24T00:00:00+08:00">
                Published: Thu 24 December 2015
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="http://synckey.name/author/andy.html">Andy</a>
        </address>
<p>In <a href="http://synckey.name/category/machinelearning.html">machinelearning</a>.</p>
<p>tags: <a href="http://synckey.name/tag/machine-learning.html">machine learning</a> <a href="http://synckey.name/tag/technology.html">technology</a> <a href="http://synckey.name/tag/logistic-regression.html">logistic regression</a> </p>
</footer><!-- /.post-info -->                <div class="highlight"><pre><span></span><span class="n">a</span><span class="p">=</span><span class="mi">2</span><span class="p">;</span>
<span class="n">x</span><span class="p">=</span><span class="o">-</span><span class="mi">10</span><span class="p">:</span><span class="mf">0.1</span><span class="p">:</span><span class="mi">10</span><span class="p">;</span>
<span class="n">y</span><span class="p">=</span><span class="mf">1.</span><span class="o">/</span><span class="p">[</span><span class="mi">1</span><span class="o">+</span><span class="nb">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="o">.*</span><span class="n">x</span><span class="p">)];</span>
<span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s">&#39;b&#39;</span><span class="p">);</span>
<span class="n">grid</span> <span class="n">on</span><span class="p">;</span>
</pre></div>


<p><p align="center">
<img src="/static/images/sigmoid.svg" alt="sigmoid"  width="50%" />
</p></p>
                <a class="readmore" href="http://synckey.name/plot-sigmoid-in-matlab.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="http://synckey.name/where-does-sigmoid-come-from.html" rel="bookmark"
                           title="Permalink to Where does sigmoid come from">Where does sigmoid come from</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2015-12-24T00:00:00+08:00">
                Published: Thu 24 December 2015
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="http://synckey.name/author/andy.html">Andy</a>
        </address>
<p>In <a href="http://synckey.name/category/machinelearning.html">machinelearning</a>.</p>
<p>tags: <a href="http://synckey.name/tag/machine-learning.html">machine learning</a> <a href="http://synckey.name/tag/technology.html">technology</a> <a href="http://synckey.name/tag/logistic-regression.html">logistic regression</a> </p>
</footer><!-- /.post-info -->                <blockquote>
<p>主要根据Andrew Ng的教学讲义整理。</p>
</blockquote>
<p>逻辑回归(Logistic Regression)是机器学习中用的最广泛的算法之一，其中 $sigmoid$ 函数是逻辑回归用到的核心函数，它的输出形状如下:
<p align="center">
<img src="/static/images/sigmoid.svg" alt="sigmoid"  width="60%" />
</p>
书里面都说它的输出可以认为是预测的概率，但是，为什么是$sigmoid$，它是从哪来的呢？为什么可以它做二分类?书里面好像都没有说呢。</p>
<h3>1.逻辑回归的建模</h3>
<p>首先从逻辑回归($Logistic$ $Regression$)的基本假设说起。在二分类中，我们假设 $y \in \lbrace0,1\rbrace$,在给定 $x$ 的情况下，很自然
就想到使用 $Bernoulli$ 对 $y$ 的条件分布进行建模。$Bernoulli$
分布可以认为是二项分布一个特例($n=1$)，其结果只能取$0$或1。假设实验成功的概率为$p$,则$Bernoulli …</p>
                <a class="readmore" href="http://synckey.name/where-does-sigmoid-come-from.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>
                </ol><!-- /#posts-list -->
                </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="http://synckey.name/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

    <script type="text/javascript">
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-55913313-1', 'auto');
    ga('send', 'pageview');
    </script>
</body>
</html>